{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. Light GBM\n",
    " \n",
    " Before discussing how Light GBM works, let’s first understand why we need this algorithm when we have so many others (like the ones we have seen above). Light GBM beats all the other algorithms when the dataset is extremely large. Compared to the other algorithms, Light GBM takes lesser time to run on a huge dataset.\n",
    "\n",
    "LightGBM is a gradient boosting framework that uses tree-based algorithms and follows leaf-wise approach while other algorithms work in a level-wise approach pattern. The images below will help \n",
    "you understand the difference in a better way.\n",
    "\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/11194110/leaf.png\" />\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/11194227/depth-768x267.png\" />\n",
    "\n",
    "\n",
    "Leaf-wise grwth may cause over-fitting on smaller datasets but that can be avoided by using the ‘max_depth’ parameter for learning. You can read more about Light GBM and its comparison with XGB in this article.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Parameters\n",
    "\n",
    "    num_iterations:\n",
    "        It defines the number of boosting iterations to be performed.\n",
    "    num_leaves :\n",
    "        This parameter is used to set the number of leaves to be formed in a tree.\n",
    "        In case of Light GBM, since splitting takes place leaf-wise rather than depth-wise, num_leaves must be smaller than 2^(max_depth), otherwise, it may lead to overfitting.\n",
    "    min_data_in_leaf :\n",
    "        A very small value may cause overfitting.\n",
    "        It is also one of the most important parameters in dealing with overfitting.\n",
    "    max_depth:\n",
    "        It specifies the maximum depth or level up to which a tree can grow.\n",
    "        A very high value for this parameter can cause overfitting.\n",
    "    bagging_fraction:\n",
    "        It is used to specify the fraction of data to be used for each iteration.\n",
    "        This parameter is generally used to speed up the training.\n",
    "    max_bin :\n",
    "        Defines the max number of bins that feature values will be bucketed in.\n",
    "        A smaller value of max_bin can save a lot of time as it buckets the feature values in discrete bins which is computationally inexpensive.\n",
    "\n",
    " -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
